import streamlit as st
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import ChatMessage
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.prompts import load_prompt
from dotenv import load_dotenv

# API KEY ì •ë³´ ë¡œë“œ
load_dotenv()

st.set_page_config(page_title="ìƒë‹´ Chatbot ğŸ’¬", page_icon="ğŸ’¬")
st.title("ìƒë‹´ Chatbot ğŸ’¬")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

def print_history():
    for msg in st.session_state["messages"]:
        st.chat_message(msg.role).write(msg.content)

def add_history(role, content):
    st.session_state["messages"].append(ChatMessage(role=role, content=content))

# ì²´ì¸ì„ ìƒì„±í•©ë‹ˆë‹¤. (ChatOpenAI ë¶€ë¶™ì— agentë¥¼ ì¶”ê°€í•´ì£¼ë©´ agentì‚¬ìš©ê°€ëŠ¥)
def create_chain(prompt, model):
    chain = prompt | ChatOpenAI(model_name=model) | StrOutputParser()
    return chain


with st.sidebar:
    clear_btn = st.button("ëŒ€í™”ë‚´ìš© ì´ˆê¸°í™”")

    # ëª¨ë¸ ì„ íƒ 
    model_options = ["gpt-3.5-turbo", "gpt-4o-mini",]
    selected_model = st.selectbox("ëª¨ë¸ ì„ íƒ", model_options, key="model_select")

    # í”„ë¡¬í”„íŠ¸ ì„ íƒ
    tab1, tab2 = st.tabs(["í”„ë¡¬í”„íŠ¸ ì •ì˜", "í”„ë¦¬ì…‹"])
    prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ ìƒë‹´ì‚¬ ì—­í• ì„ ë§¡ì€ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ê³ ë¯¼ê³¼ ì§ˆë¬¸ì— ê³µê°í•˜ë©°, ì ì ˆí•œ ì¡°ì–¸ê³¼ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”. ëª¨ë“  ë‹µë³€ì€ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤."""
    user_text_prompt = tab1.text_area("í”„ë¡¬í”„íŠ¸", value=prompt)
    user_text_apply_btn = tab1.button("í”„ë¡¬í”„íŠ¸ ì ìš©", key="apply1")

    # ì‚¬ìš©ìê°€ ì§ì ‘ í”„ë¡¬í”„íŠ¸ë¥¼ ì ìš©í•œ ê²½ìš°
    if user_text_apply_btn:
        tab1.markdown(f"âœ… í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤")
        prompt_template = user_text_prompt + "\n\n#Question:\n{question}\n\n#Answer:"
        prompt = PromptTemplate.from_template(prompt_template)
        st.session_state["chain"] = create_chain(prompt, selected_model)  # ëª¨ë¸ ì„ íƒ ë°˜ì˜

    # ê°œë°œìê°€ ì§€ì •í•´ë‘” í”„ë¡¬í”„íŠ¸ë¥¼ ì ìš©í•œ ê²½ìš°
    user_selected_prompt = tab2.selectbox("í”„ë¦¬ì…‹ ì„ íƒ", ["ì¹œì ˆí•œì§€ì¸", "ê°‘ìƒì„ ì•”ì „ë¬¸ì˜"])
    user_selected_apply_btn = tab2.button("í”„ë¡¬í”„íŠ¸ ì ìš©", key="apply2")
    if user_selected_apply_btn:
        tab2.markdown(f"âœ… í”„ë¡¬í”„íŠ¸ê°€ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤")
        prompt = load_prompt(f"prompts/{user_selected_prompt}.yaml", encoding="utf8")
        st.session_state["chain"] = create_chain(prompt, selected_model)  # ëª¨ë¸ ì„ íƒ ë°˜ì˜

# ëŒ€í™”ë‚´ìš© ì´ˆê¸°í™” ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ëŒ€í™”ë‚´ìš© ì´ˆê¸°í™” ì‹œí‚´
if clear_btn:
    st.session_state["messages"].clear()

print_history()

if "chain" not in st.session_state:
    # user_prompt
    prompt_template = user_text_prompt + "\n\n#Question:\n{question}\n\n#Answer:"
    prompt = PromptTemplate.from_template(prompt_template)
    st.session_state["chain"] = create_chain(prompt, selected_model)  # ëª¨ë¸ ì„ íƒ ë°˜ì˜


if user_input := st.chat_input():
    add_history("user", user_input)
    st.chat_message("user").write(user_input)
    with st.chat_message("assistant"):
        chat_container = st.empty()

        stream_response = st.session_state["chain"].stream(
            {"question": user_input}
        )  # ë¬¸ì„œì— ëŒ€í•œ ì§ˆì˜
        ai_answer = ""
        for chunk in stream_response:
            ai_answer += chunk
            chat_container.markdown(ai_answer)
        add_history("ai", ai_answer)
